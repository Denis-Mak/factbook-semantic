Factbook semantic search
========================

Весь проект выполняет функцию семантического поискового движка (в качестве контекстного используется [Sphinx](http://sphinxsearch.com)).
Классы необходимые для построения индекса и поиска по нему, все находятся в этом проекте.

### Построение и устройство индекса
Индекс состоит из двух частей, обе размещены в таблицах Cassandra:
* semantic_index_v2 - инверсный индекс, где по mem можно быстро найти факты, в которых он присутствует
* idiom_v2 - список всех уникальных словосочетаний, для всех словарей. Он используется для поиска синонимов.

По содержимому и названию колонок понятно что в них находится, дам всего несколько комментариев:
* в колонке random_index лежит бинарное представление случайного вектора, закодированное так: позиции единиц в векторе
(так как он сильно разряжен и единиц там немного), длина вектора не кодируется так как они все одинаковой длинны и это константа,
 которую можно считать из ```Stem.RI_VECTOR_LENGTH```. Все это закодировано в виде строки при помощи Base64.
* в колонке mem лежит в формате JSON сам массив memId и сравнения с ним идут как со строкой

Остальные поля ровно такие же как и в контекстном поиске и подробно описаны в [factbook-search](https://github.com/Denis-Mak/factbook-search/blob/master/doc/details.md)


Строится индекс в два этапа сначала заполняется одна таблица, потом из нее другая. Первой заполняется ```semantic_index_v2```
из таблицы фактов. Для этого нужно в Spark запустить скрипт ```BuildSemanticIndex```:

```
/opt/spark-1.4.1/bin/spark-submit --class it.factbook.semantic.BuildSemanticIndex --master spark://XX.XX.XX.XX:7077 /run/factbook-semantic-1.0-SNAPSHOT.jar &
```

После того как закончит работу этот скрипт (около 15 часов занимает обработка всех фактов), нужно запустить ```BuildIdiomIndex```:

```
/opt/spark-1.4.1/bin/spark-submit --class it.factbook.semantic.BuildIdiomIndex --master spark://XX.XX.XX.XX:7077 /run/factbook-semantic-1.0-SNAPSHOT.jar &
```

### Поиск
Для выполнения семантического поиска запускается job в Spark и распределенно выполняются две фазы поиска:
* поиск синонимов
* поиск фактов, содержащих синонимы

По сути это удаленный исполнитель job Spark-а, то есть в обычном случае нужно чтобы запустить job в Spark нужно загрузить
java-класс в кластер при помощи команды ```spark-submit```, в случае semantic search job уже загружен и ожидает команды,
слушая network socket. После получения команды запускается отдельный thread на поиск, который возвращает результат клиенту.

##### Поиск синонимов
При первом поиске в память всех нод кластера загружается список синонимов, у каждой ноды своя часть списка. В дальнейшем
 синонимы считываются из памяти.
Синонимы ищутся по близости смыслов, то есть по количеству совпавших memId из вектора mem. Так как задача перебора всех
векторов для всех слов очень трудоемкая 2 млн * 8 memId * 40 строк профиля, то для ее упрощения мы используем сравнение
бинарных векторов, сгенерированных для каждого memId. Обоснование этого метода можно прочитать [здесь](https://www.cs.umd.edu/~mount/Papers/dist.pdf)

Синонимами считаются слова у которых хэммингово расстояние между векторами не больше 16, а количество общих memId не менее 4.
После того как найдены все синонимы по всем линиям профиля, они группируются по линиям профиля по которым быди найдены.
Потом отсекаются ТОП-50 наиболее весомых синонима, это делается для того, чтобы отсечь всякие назавания объектов и персон,
у которых синонимов несколько тысяч.

##### Поиск фактов
Найденные синонимы при помощи метода драйвера Cassandra для Spark ```joinWithCassandraTable``` пересекаются с семантическим
 индексом при этом ключ состоит не только из случайного вектора, а из трех компонентов:
* golem (словарь из которого взят mem)
* random_index (случайный вектор)
* mem (непосредственно сам mem)

Далее найденные факты упаковываются в класс ```Match``` (в тот же самый, что и результаты контекстного поиска) и возвращаются
клиенту в виде списка в формате JSON.

### Как пользоваться сервисом семантического поиска
Для получения результатов семантического поиска в самой системе написан адаптер ```SemanticSearchCassandraImpl``` в проекте
factbook-search, который взаимодействует с сервисом. Но можно запустить поиск написав своего клиента, который будет отправлять
на порт, указанный в конфигурации ```cql.properties``` (по-умолчанию 9406) JSON вида:
```
{
    "actionCode": 1,
    "profile": {
      "id": 1,
      "query": "",
      "lines": [
        {
          "id": 25853,
          "words": [
            [
              {
                "id": 167398,
                "word": "неизбежно",
                "lang": "UNKNOWN",
                "golem": "WIKI_RU",
                "ending": 313,
                "tag": 17,
                "root": "(неизбеж",
                "stemIdf": 12,
                "stemId": 12206,
                "semId": 207
              },
              {
                "id": 3307080,
                "word": "падёт",
                "lang": "UNKNOWN",
                "golem": "WIKI_RU",
                "ending": 445,
                "tag": 17,
                "root": "(паде",
                "stemIdf": 15,
                "stemId": 6316,
                "semId": 218
              }
            ]
          ],
          "mem": [207, 218, 1893, 4775, 230, 4882, 3009, 482],
          "weight": 1164313
        }
      ]
    }
}
```
, где в поле ```profile``` лежит в формате JSON объект класса  ```SearchProfile```, а в поле ```actionCode``` код типа поиска
1 - обычный поиск фактов по семантике; 2 - поиск всех синонимов по всем словосочетаниям из строчек профиля.

 ### Javadoc reference
 * [Javadoc API - current version](http://denis-mak.github.io/factbook-semantic/current/docs/index.html)

 * [Модель данных Cassandra (схема doccache, таблицы semantic_index_v2 и idiom_v2))](http://denis-mak.github.io/factbook/current/datamodel/factbook-cassandra-data-structure.png)

